{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d74346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96e960ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Smart_Essay_Scorer/data/processed/cleaned_essays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65577dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>word_count_capped</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>396</td>\n",
       "      <td>17</td>\n",
       "      <td>396</td>\n",
       "      <td>author suggests studying venus worthy dangerou...</td>\n",
       "      <td>23.294118</td>\n",
       "      <td>1331</td>\n",
       "      <td>3.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>200</td>\n",
       "      <td>nasa fighting alble venus researching diffrent...</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>516</td>\n",
       "      <td>2.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>371</td>\n",
       "      <td>31</td>\n",
       "      <td>371</td>\n",
       "      <td>evening star brightest point light sky night v...</td>\n",
       "      <td>11.967742</td>\n",
       "      <td>1221</td>\n",
       "      <td>3.291105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>10</td>\n",
       "      <td>224</td>\n",
       "      <td>author support idea reading passage suggests v...</td>\n",
       "      <td>22.400000</td>\n",
       "      <td>704</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>219</td>\n",
       "      <td>7</td>\n",
       "      <td>219</td>\n",
       "      <td>author support idea state text strivivng meet ...</td>\n",
       "      <td>31.285714</td>\n",
       "      <td>776</td>\n",
       "      <td>3.543379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  word_count  sent_count  word_count_capped  \\\n",
       "0      4         396          17                396   \n",
       "1      2         200          13                200   \n",
       "2      3         371          31                371   \n",
       "3      2         224          10                224   \n",
       "4      2         219           7                219   \n",
       "\n",
       "                                          text_clean  words_per_sentence  \\\n",
       "0  author suggests studying venus worthy dangerou...           23.294118   \n",
       "1  nasa fighting alble venus researching diffrent...           15.384615   \n",
       "2  evening star brightest point light sky night v...           11.967742   \n",
       "3  author support idea reading passage suggests v...           22.400000   \n",
       "4  author support idea state text strivivng meet ...           31.285714   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0        1331         3.361111  \n",
       "1         516         2.580000  \n",
       "2        1221         3.291105  \n",
       "3         704         3.142857  \n",
       "4         776         3.543379  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c92f8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text_clean'].str.strip().str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b34265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: ' '.join([w for w in x.split() if w not in ENGLISH_STOP_WORDS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2828b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Faiz\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81acd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average words per sentence\n",
    "df['words_per_sentence'] = df['word_count'] / df['sent_count'].replace(0,1)\n",
    "\n",
    "# Character count (optional)\n",
    "df['char_count'] = df['text_clean'].apply(len)\n",
    "\n",
    "# Average word length\n",
    "df['avg_word_length'] = df['char_count'] / df['word_count'].replace(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c315a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (24728, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "x_text = tfidf.fit_transform(df['text_clean'])\n",
    "print(\"TF-IDF shape:\", x_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1239fef",
   "metadata": {},
   "source": [
    "### Combine numeric + text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd08135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Numeric features\n",
    "x_numeric = df[['word_count', 'sent_count', 'word_count_capped', 'words_per_sentence', 'avg_word_length']].values\n",
    "\n",
    "# Combine with TF-IDF\n",
    "X_final = hstack([x_numeric, x_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c58613d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "import numpy as np\n",
    "\n",
    "save_npz(\"/Smart_Essay_Scorer/data/processed/X_final.npz\", X_final)\n",
    "np.save(\"/Smart_Essay_Scorer/data/processed/y.npy\", df['score'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f9eff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>word_count_capped</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>396</td>\n",
       "      <td>17</td>\n",
       "      <td>396</td>\n",
       "      <td>author suggests studying venus worthy dangerou...</td>\n",
       "      <td>23.294118</td>\n",
       "      <td>1331</td>\n",
       "      <td>3.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>13</td>\n",
       "      <td>200</td>\n",
       "      <td>nasa fighting alble venus researching diffrent...</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>516</td>\n",
       "      <td>2.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>371</td>\n",
       "      <td>31</td>\n",
       "      <td>371</td>\n",
       "      <td>evening star brightest point light sky night v...</td>\n",
       "      <td>11.967742</td>\n",
       "      <td>1221</td>\n",
       "      <td>3.291105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>10</td>\n",
       "      <td>224</td>\n",
       "      <td>author support idea reading passage suggests v...</td>\n",
       "      <td>22.400000</td>\n",
       "      <td>704</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>219</td>\n",
       "      <td>7</td>\n",
       "      <td>219</td>\n",
       "      <td>author support idea state text strivivng meet ...</td>\n",
       "      <td>31.285714</td>\n",
       "      <td>776</td>\n",
       "      <td>3.543379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  word_count  sent_count  word_count_capped  \\\n",
       "0      4         396          17                396   \n",
       "1      2         200          13                200   \n",
       "2      3         371          31                371   \n",
       "3      2         224          10                224   \n",
       "4      2         219           7                219   \n",
       "\n",
       "                                          text_clean  words_per_sentence  \\\n",
       "0  author suggests studying venus worthy dangerou...           23.294118   \n",
       "1  nasa fighting alble venus researching diffrent...           15.384615   \n",
       "2  evening star brightest point light sky night v...           11.967742   \n",
       "3  author support idea reading passage suggests v...           22.400000   \n",
       "4  author support idea state text strivivng meet ...           31.285714   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0        1331         3.361111  \n",
       "1         516         2.580000  \n",
       "2        1221         3.291105  \n",
       "3         704         3.142857  \n",
       "4         776         3.543379  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "126c639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"/Smart_Essay_Scorer/data/processed/essays_featured.csv\", index=False)\n",
    "print(\"✅ Processed dataset saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
